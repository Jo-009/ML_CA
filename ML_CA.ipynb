{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "name": "Jotestcode-Tensorflow Code.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jo-009/ML_CA/blob/Ver.2/ML_CA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53ef8e64"
      },
      "source": [
        "## CA Specifications\n",
        "1. A Fruits dataset is provided for this project, and it has images of (1) \n",
        "   apples, (2)oranges, (3) bananas and (4) a mix of apples, oranges and \n",
        "   bananas.\n",
        "2. Your task is to implement a CNN to recognize the 4 classes accurately.\n",
        "3. Use the images in the “train” folder to train your image classifier.\n",
        "4. Then, test the accuracy of your image classifier using images from the \n",
        "   “test” folder.\n",
        "5. Document all your experiments and results. For example, what was done to\n",
        "   increase the accuracy of your image classifier (e.g. image augmentation).\n",
        "6. Use Matplotlib to produce any plots that help the reader understand your\n",
        "   work better.\n",
        "   \n",
        "### Submission\n",
        "The deadline for this project is <b>28 Nov 2021, 6pm</b>.\n",
        "Please name your submission as <Your_Team_Number><A_or_B>.ipynb. For\n",
        "example, if you are in Team 1A, then your filename should be Team1A.ipynb."
      ],
      "id": "53ef8e64"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZWn23PxXuTb"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image, ImageOps"
      ],
      "id": "TZWn23PxXuTb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fd28ede"
      },
      "source": [
        "### Preprocessing and Loading Data\n",
        "\n",
        "Derive x_train,x_test,x_val,y_train,y_test and y_val \n",
        "\n",
        "<b>x_train</b>: Numpy arrays of the images of the training dataset\n",
        "\n",
        "<b>y_train</b>: Labels of the training dataset\n",
        "\n",
        "<b>x_test</b>: Numpy arrays of the images of the testing dataset\n",
        "\n",
        "<b>y_test</b>: Labels of the testing dataset\n",
        "\n",
        "<b>x_val</b>: Numpy arrays of the images of the validation dataset\n",
        "\n",
        "<b>y_val</b>: Labels of the validation dataset"
      ],
      "id": "9fd28ede"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceSWGug0a2nC"
      },
      "source": [
        "train_img_path = '/content/drive/MyDrive/Colab Notebooks/train/'\n",
        "test_img_path = '/content/drive/MyDrive/Colab Notebooks/test/1/' "
      ],
      "id": "ceSWGug0a2nC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1EFV6LcefRK"
      },
      "source": [
        "### Testing one img"
      ],
      "id": "Q1EFV6LcefRK"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOvqWx9TbBND"
      },
      "source": [
        "# #test one img\n",
        "# img = Image.open(train_img_path + 'mixed_4.jpg')\n",
        "# img"
      ],
      "id": "rOvqWx9TbBND",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vabP3eWbo23"
      },
      "source": [
        "# np_img = np.array(img)\n",
        "# #plt.imshow(np_img)\n",
        "# np_img.shape"
      ],
      "id": "1vabP3eWbo23",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPdPe3qvcGaQ"
      },
      "source": [
        "# # normalize pixels values to between 0.0 to 1.0\n",
        "# np_img_norm = np_img / 255\n",
        "# np_img_norm"
      ],
      "id": "HPdPe3qvcGaQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGjLDdxEdnsM"
      },
      "source": [
        "# # crop and resize img\n",
        "# width, height = img.size\n",
        "# pad = 20    # pixels\n",
        "\n",
        "# img_crop = img.crop((pad, pad, width-pad, height-pad))\n",
        "# img_mod = img_crop.resize((650,650))\n",
        "\n",
        "# img_mod.size"
      ],
      "id": "DGjLDdxEdnsM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mmafiLbdyAP"
      },
      "source": [
        "# # plot modified img\n",
        "# plt.subplots(figsize=(2,2))\n",
        "# plt.imshow(img_mod)"
      ],
      "id": "6mmafiLbdyAP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s26VazgziSj3"
      },
      "source": [
        "### Load data"
      ],
      "id": "s26VazgziSj3"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19cb9b63"
      },
      "source": [
        "train_ds_raw = os.listdir('/content/drive/MyDrive/Colab Notebooks/train/')\n",
        "test_ds_raw = os.listdir('/content/drive/MyDrive/Colab Notebooks/test/1/')"
      ],
      "id": "19cb9b63",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifdGO1wLZI36"
      },
      "source": [
        "train_ds_raw"
      ],
      "id": "ifdGO1wLZI36",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3ys7pFNvv1d"
      },
      "source": [
        "type(train_ds_raw), len(train_ds_raw)"
      ],
      "id": "r3ys7pFNvv1d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltlkR0Avwm2r"
      },
      "source": [
        "### Create X_train"
      ],
      "id": "ltlkR0Avwm2r"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_aVwgiMvSBn"
      },
      "source": [
        "filenames = []\n",
        "for label in train_ds_raw:\n",
        "    if label[-3:] == 'xml': \n",
        "        continue              # only take jpeg\n",
        "    else:\n",
        "        filenames.append(train_img_path + label)"
      ],
      "id": "G_aVwgiMvSBn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwJueec5fL3Y"
      },
      "source": [
        "# filenames\n",
        "len(filenames)"
      ],
      "id": "jwJueec5fL3Y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiE5sRB-wvBX"
      },
      "source": [
        "### Create y_train label"
      ],
      "id": "FiE5sRB-wvBX"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e91ehIK9vLku"
      },
      "source": [
        "y_train_label = []\n",
        "\n",
        "for label in train_ds_raw:\n",
        "    if label[-3:] == 'xml': \n",
        "        continue              #if xml, ignore\n",
        "    arr = label.split('_')    # else, str manipulation \n",
        "    y_train_label.append(arr[0])\n"
      ],
      "id": "e91ehIK9vLku",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57042e0f"
      },
      "source": [
        "#y_train_label\n",
        "len(filenames), len(y_train_label)"
      ],
      "id": "57042e0f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLh0xe_qxTy_"
      },
      "source": [
        "### Create df to visualize datasets"
      ],
      "id": "BLh0xe_qxTy_"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vg9zB5CvxYpU"
      },
      "source": [
        "df = pd.DataFrame(columns=['filenames'], data=filenames)"
      ],
      "id": "vg9zB5CvxYpU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8hnNB_excjB"
      },
      "source": [
        "df['y_train_label'] = y_train_label"
      ],
      "id": "y8hnNB_excjB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4rqMNaFxgTs"
      },
      "source": [
        "df"
      ],
      "id": "a4rqMNaFxgTs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuOtqL4kxkmz"
      },
      "source": [
        "img = cv2.imread(filenames[10], cv2.IMREAD_COLOR)\n",
        "img.shape"
      ],
      "id": "VuOtqL4kxkmz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqKIl1wyxzEP"
      },
      "source": [
        "### Plot Histogram to set size of images"
      ],
      "id": "oqKIl1wyxzEP"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5cf9753"
      },
      "source": [
        "# plot histogram\n",
        "# decide which is the more common size for img\n",
        "# Getting the dimensions of all the image into a list\n",
        "dim1 = []\n",
        "dim2 = []\n",
        "colors = []\n",
        "\n",
        "for img_filename in filenames:\n",
        "    x, y, c = plt.imread(img_filename).shape # height width color\n",
        "    dim1.append(x)\n",
        "    dim2.append(y)\n",
        "    colors.append(c)"
      ],
      "id": "f5cf9753",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fg5YDbf3x-rp"
      },
      "source": [
        "dim1 = np.array(dim1)\n",
        "dim2 = np.array(dim2)\n",
        "colors = np.array(colors)"
      ],
      "id": "fg5YDbf3x-rp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aF8QZ53zyBBI"
      },
      "source": [
        "dim1.max(), dim2.max(), colors.mean()"
      ],
      "id": "aF8QZ53zyBBI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ab0615dd"
      },
      "source": [
        "sns.jointplot(x=dim1, y=dim2);"
      ],
      "id": "ab0615dd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iO5DwUcYyHGa"
      },
      "source": [
        "dim1.mean(), dim2.mean()"
      ],
      "id": "iO5DwUcYyHGa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtAm3FuiyJQf"
      },
      "source": [
        "resize according to findings:\n",
        "*Taking the mean of the image size, we set the image size to be 650 by 650 by 3 for easier computation*\n",
        "**image_size = (650, 650)**"
      ],
      "id": "OtAm3FuiyJQf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoXpWs5DzNB4"
      },
      "source": [
        "### Resize images to proper and similar size and create x_train"
      ],
      "id": "LoXpWs5DzNB4"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WTcpqAik5Od"
      },
      "source": [
        "# # test greyscale and resize on 1 img\n",
        "# img = Image.open(filenames[1])\n",
        "# greyscale_img = img.convert('L')\n",
        "# img_resized = greyscale_img.resize((650,650))\n",
        "# img_resized"
      ],
      "id": "_WTcpqAik5Od",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yddgi2-KzbYf"
      },
      "source": [
        "# x_train = None\n",
        "\n",
        "# for i in range(len(filenames)):\n",
        "#     img_raw = Image.open(filenames[i])  \n",
        "#     greyscale_img = ImageOps.grayscale(img_raw)\n",
        "#     img_reshaped = greyscale_img.resize((650, 650))   \n",
        "#     if x_train is None:\n",
        "#         x_train = img_reshaped\n",
        "#     else:\n",
        "#         x_train = np.concatenate((x_train, img_reshaped))"
      ],
      "id": "Yddgi2-KzbYf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvY4WiREuixE"
      },
      "source": [
        "x_train = None\n",
        "\n",
        "for i in range(len(y_train_label)):\n",
        "    img_raw = cv2.imread(filenames[i], cv2.IMREAD_COLOR)\n",
        "    img_reshaped = cv2.resize(img_raw,(650, 650), cv2.INTER_NEAREST)\n",
        "    img_reshaped = cv2.cvtColor(img_reshaped, cv2.COLOR_BGR2RGB)\n",
        "    if x_train is None:\n",
        "        x_train = img_reshaped\n",
        "    else:\n",
        "        x_train = np.concatenate((x_train, img_reshaped))"
      ],
      "id": "hvY4WiREuixE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANhgnkGSyQ0k"
      },
      "source": [
        "Verify data shaped correctly "
      ],
      "id": "ANhgnkGSyQ0k"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yj2vRp1J68Fj"
      },
      "source": [
        "x_train = x_train.reshape(-1, 650, 650, 3)\n",
        "x_train.shape"
      ],
      "id": "Yj2vRp1J68Fj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fh2Wz05BJxfT"
      },
      "source": [
        "Verify that data is shaped correctly by randomly retrieving an individual data to view"
      ],
      "id": "Fh2Wz05BJxfT"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vCcC-CSKCvv"
      },
      "source": [
        "# img2 = Image.fromarray(x_train[1])\n",
        "# --> bug in scipy so shape can throw error\n",
        "img2 = np.array(Image.fromarray((x_train[1] * 255).astype(np.uint8)).convert('RGB'))\n",
        "plt.subplots(figsize=(2,2))\n",
        "plt.imshow(img2)"
      ],
      "id": "9vCcC-CSKCvv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K61EcIxjH8Mc"
      },
      "source": [
        "**Determine max value of each cell and min before normalizing**"
      ],
      "id": "K61EcIxjH8Mc"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "336393cd"
      },
      "source": [
        "x_train.max(), x_train.min()"
      ],
      "id": "336393cd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1Iwp-eAIIDk"
      },
      "source": [
        "**Normalize dataset**"
      ],
      "id": "s1Iwp-eAIIDk"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y15ugtfnILRB"
      },
      "source": [
        "x_train = x_train/255\n",
        "print(x_train.shape)"
      ],
      "id": "Y15ugtfnILRB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64a1cb65"
      },
      "source": [
        "One-Hot Encoding data using keras to_categorical"
      ],
      "id": "64a1cb65"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3Z2Ti8TwsuQ"
      },
      "source": [
        "#labels in str\n",
        "cat = np.unique(y_train_label)\n",
        "cat"
      ],
      "id": "t3Z2Ti8TwsuQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Yjzg3B6Ip29"
      },
      "source": [
        "n_labels = len(cat)\n",
        "n_labels"
      ],
      "id": "3Yjzg3B6Ip29",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2raB5SCod-j"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "\n",
        "#instantiate one hot encoding\n",
        "encoder = LabelEncoder()\n",
        "#fit\n",
        "encoder.fit(y_train_label)\n",
        "#transform\n",
        "data = encoder.transform(y_train_label)\n",
        "y_train = tf.keras.utils.to_categorical(data)\n",
        "\n",
        "print(y_train) "
      ],
      "id": "u2raB5SCod-j",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yj28XSAfpVt_"
      },
      "source": [
        "# to vosualize the labels\n",
        "categories = pd.DataFrame(data=y_train,\n",
        "                 columns=encoder.classes_)\n",
        "\n",
        "print(categories)"
      ],
      "id": "yj28XSAfpVt_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74168da3"
      },
      "source": [
        "### Defining Model Architecture\n",
        "Things like: \n",
        "- how many convolutional layers do we want\n",
        "- what should be the activation function for each layer\n",
        "- how many hidden units should each layer have etc"
      ],
      "id": "74168da3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4c8bf940"
      },
      "source": [
        "#### Construct CNN Model\n",
        "\n",
        "- Create an empty Neural Network via Sequential()\n",
        "- Add more layers to 'model' obj to turn it into CNN\n",
        "- First layer--> convolutional layer(filters,kernal_size,activation,input_shape)\n"
      ],
      "id": "4c8bf940"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9a426198"
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(filters=32, \n",
        "                                kernel_size=(3,3),\n",
        "                                activation = 'relu', \n",
        "                                input_shape= (650,650,3)))\n",
        "model.add(tf.keras.layers.Conv2D(filters=32, \n",
        "                                 kernel_size=(5,5),\n",
        "                                activation = 'relu', \n",
        "                                input_shape= (650,650,3)))\n",
        "# model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3),\n",
        "#                                 activation = 'relu', \n",
        "#                                 input_shape= (650,650,3)))\n",
        "# model pooling, dropout, dense (need to flatten first) \n",
        "model.add(tf.keras.layers.Flatten())\n",
        "# model.add(tf.keras.layers.Dense(512,activation='relu'))\n",
        "# model.add(tf.keras.layers.Dense(1,activation='sigmoid')) \n",
        "model.add(tf.keras.layers.Dense(units=1, activation='softmax'))"
      ],
      "id": "9a426198",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e08df059"
      },
      "source": [
        "model.summary()"
      ],
      "id": "e08df059",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-ks3KRDPvnq"
      },
      "source": [
        "- When using Softmax as the activation function as the last layer, our loss function should be ‘categorical_crossentropy’\n",
        "- Optimizers are algorithms to change the weights and the learning rate of our neural network; ‘adam’ is a good choice\n",
        "- When determining the accuracy of a prediction, use ‘accuracy’ as the metrics as we can count the number of times the neural network has given a correct prediction"
      ],
      "id": "Z-ks3KRDPvnq"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRmxVDD8P0BK"
      },
      "source": [
        "#compiling the CNN\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "id": "QRmxVDD8P0BK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "825f6e47"
      },
      "source": [
        "### Train the Model\n",
        "\n",
        "Require training images and their corresponding true labels, validation images and their corresponding true labels (we use these labels only to validate the model and not during the training phase). We also define the number of epochs in this step. For starters, we will run the model for 10 epochs (you can change the number of epochs later)."
      ],
      "id": "825f6e47"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9d6177bd"
      },
      "source": [
        "#### can consider using k-means to calculate epochs"
      ],
      "id": "9d6177bd"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1a28d716"
      },
      "source": [
        "# x_train = np.array(x_train)\n",
        "# y_train = np.array(y_train)\n",
        "fitting = model.fit(x=x_train, y=y_train, epochs=15)"
      ],
      "id": "1a28d716",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gKH1jbLaSqe"
      },
      "source": [
        "#### Estimate model's performance and predict classes\n",
        "- load test data (img) and go through pre-processing \n",
        "      # test = pd.read_csv('test.csv')\n",
        "- read and store all test images\n",
        "      # test_image = []\n",
        "      # for i in tqdm(range(test.shape[0])):\n",
        "      # img = image.load_img('test/'+test['id'][i].astype('str')+'.png', target_size=(28,28,1), grayscale=True)\n",
        "      # img = image.img_to_array(img)\n",
        "      # img = img/255\n",
        "      # test_image.append(img)\n",
        "      # test = np.array(test_image) -->\n",
        "- make predictions\n",
        "      # prediction = model.predict_classes(test)\n",
        "\n"
      ],
      "id": "7gKH1jbLaSqe"
    }
  ]
}